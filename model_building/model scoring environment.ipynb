{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import metrics, tree, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold,cross_val_score,train_test_split,LeaveOneOut\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from statistics import mean\n",
    "\n",
    "from data_load import *\n",
    "from dictionaries import *\n",
    "from score_models import *\n",
    "\n",
    "import datetime\n",
    "a = datetime.datetime.now()\n",
    "time_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\n",
    "                'problem_type',\n",
    "                'creative',\n",
    "                'outdoors',\n",
    "                'career',\n",
    "                'group_work',\n",
    "                'liked_courses',\n",
    "                'disliked_courses',\n",
    "                'programming',\n",
    "                'join_clubs',\n",
    "                'not_clubs',\n",
    "                'liked_projects',\n",
    "                'disliked_projects',\n",
    "                'tv_shows',\n",
    "                'alternate_degree',\n",
    "                'expensive_equipment',\n",
    "                'drawing',\n",
    "                'essay',\n",
    "                'architecture',\n",
    "                'automotive',\n",
    "                'business',\n",
    "                'construction',\n",
    "                'health',\n",
    "                'environment',\n",
    "                'manufacturing',\n",
    "                'technology',\n",
    "                'program'\n",
    "                ]\n",
    "\n",
    "ohe_main =  [\n",
    "            'problem_type',\n",
    "            'creative',\n",
    "            'outdoors',\n",
    "            'career',\n",
    "            'group_work',\n",
    "            'liked_courses',\n",
    "            'disliked_courses',\n",
    "            'programming',\n",
    "            'join_clubs',\n",
    "            'not_clubs',\n",
    "            'liked_projects',\n",
    "            'disliked_projects',\n",
    "            'tv_shows',\n",
    "            'alternate_degree',\n",
    "            'expensive_equipment',\n",
    "            'drawing',\n",
    "            'essay'\n",
    "        ]\n",
    "\n",
    "m0 =  [\n",
    "        'problem_type', \n",
    "        'creative', \n",
    "        'outdoors', \n",
    "        'career',\n",
    "        'group_work', \n",
    "        'liked_courses', \n",
    "        'disliked_courses', \n",
    "        'programming',\n",
    "        'join_clubs', \n",
    "        'not_clubs', \n",
    "        'liked_projects',\n",
    "        'disliked_projects',\n",
    "        'tv_shows', \n",
    "        'alternate_degree', \n",
    "        'expensive_equipment', \n",
    "        'drawing',\n",
    "        'essay'\n",
    "        ]\n",
    "m0 = [value for value in m0 if value in  column_list]\n",
    "\n",
    "m2 =  [\n",
    "        'career',\n",
    "        'liked_courses', \n",
    "        'join_clubs', \n",
    "        'alternate_degree' \n",
    "        ] \n",
    "m2 = [value for value in m2 if value in  column_list]\n",
    "\n",
    "m3 =  [\n",
    "        'career'\n",
    "        ] \n",
    "m3 = [value for value in m3 if value in  column_list]\n",
    "\n",
    "m4 =  [\n",
    "        'liked_courses'\n",
    "        ] \n",
    "m4 = [value for value in m4 if value in  column_list]\n",
    "\n",
    "m5 =  [\n",
    "        'join_clubs'\n",
    "        ] \n",
    "m5 = [value for value in m5 if value in  column_list]\n",
    "\n",
    "m6 =  [\n",
    "        'alternate_degree' \n",
    "        ] \n",
    "m6 = [value for value in m6 if value in  column_list]\n",
    "\n",
    "m7 =  [\n",
    "        'career',\n",
    "        'liked_courses'\n",
    "        ] \n",
    "m7 = [value for value in m7 if value in  column_list]\n",
    "\n",
    "m8 =  [\n",
    "        'career',\n",
    "        'join_clubs'\n",
    "        ] \n",
    "m8 = [value for value in m8 if value in  column_list]\n",
    "\n",
    "m9 =  [\n",
    "        'career',\n",
    "        'alternate_degree' \n",
    "        ] \n",
    "m9 = [value for value in m9 if value in  column_list]\n",
    "\n",
    "m10 =  [\n",
    "        'liked_courses', \n",
    "        'join_clubs'\n",
    "        ]\n",
    "m10 = [value for value in m10 if value in  column_list]\n",
    "\n",
    "m11 =  [\n",
    "        'liked_courses',  \n",
    "        'alternate_degree'\n",
    "        ] \n",
    "m11 = [value for value in m11 if value in  column_list]\n",
    "\n",
    "m12 =  [\n",
    "        'join_clubs', \n",
    "        'alternate_degree'\n",
    "        ] \n",
    "m12 = [value for value in m12 if value in  column_list]\n",
    "\n",
    "m13 =  [\n",
    "        'career',\n",
    "        'liked_courses', \n",
    "        'join_clubs'\n",
    "        ]\n",
    "m13 = [value for value in m13 if value in  column_list]\n",
    "\n",
    "m14 =  [\n",
    "        'career',\n",
    "        'join_clubs', \n",
    "        'alternate_degree'\n",
    "        ] \n",
    "m14 = [value for value in m14 if value in  column_list]\n",
    "\n",
    "m15 =  [\n",
    "        'career',\n",
    "        'liked_courses', \n",
    "        'alternate_degree'\n",
    "        ] \n",
    "m15 = [value for value in m15 if value in  column_list]\n",
    "\n",
    "m16 =  [\n",
    "        'liked_courses', \n",
    "        'join_clubs', \n",
    "        'alternate_degree'\n",
    "        ] \n",
    "m16 = [value for value in m16 if value in  column_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the model experiment names and all of the used suffixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep the suffixes and the experiment model names updated to view all scores\n",
    "\n",
    "### It takes about 10 mins to score each experiment model name\n",
    "\n",
    "### If a new type of encoding is being tried, changes need to be made to the scoring methods. Call Ayser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment_model_names = [\n",
    "    'd0_b0_c36_v0',\n",
    "    'd0_b1_c36_v0',\n",
    "    'd0_b4_c36_v0'\n",
    "                        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class_suffixes = [\n",
    "                        'nb_le_f0_',\n",
    "                        'nb_ohe_f0_',\n",
    "                        'lrr_le_f0_',\n",
    "                        'lrr_ohe_f0_',\n",
    "                        'svm_le_f0_',\n",
    "                        'svm_ohe_f0_',\n",
    "                        'nb_m2_f0_',\n",
    "                        'lrr_m2_f0_',\n",
    "                        'svm_m2_f0_',\n",
    "                        'nb_m3_f0_',\n",
    "                        'lrr_m3_f0_',\n",
    "                        'svm_m3_f0_',\n",
    "                        'nb_m4_f0_',\n",
    "                        'lrr_m4_f0_',\n",
    "                        'svm_m4_f0_',\n",
    "                        'nb_m5_f0_',\n",
    "                        'lrr_m5_f0_',\n",
    "                        'svm_m5_f0_',\n",
    "                        'nb_m6_f0_',\n",
    "                        'lrr_m6_f0_',\n",
    "                        'svm_m6_f0_',\n",
    "                        'nb_m7_f0_',\n",
    "                        'lrr_m7_f0_',\n",
    "                        'svm_m7_f0_',\n",
    "                        'nb_m8_f0_',\n",
    "                        'lrr_m8_f0_',\n",
    "                        'svm_m8_f0_',\n",
    "                        'nb_m9_f0_',\n",
    "                        'lrr_m9_f0_',\n",
    "                        'svm_m9_f0_',\n",
    "                        'nb_m10_f0_',\n",
    "                        'lrr_m10_f0_',\n",
    "                        'svm_m10_f0_',\n",
    "                        'nb_m11_f0_',\n",
    "                        'lrr_m11_f0_',\n",
    "                        'svm_m11_f0_',\n",
    "                        'nb_m12_f0_',\n",
    "                        'lrr_m12_f0_',\n",
    "                        'svm_m12_f0_',\n",
    "                        'nb_m13_f0_',\n",
    "                        'lrr_m13_f0_',\n",
    "                        'svm_m13_f0_',\n",
    "                        'nb_m14_f0_',\n",
    "                        'lrr_m14_f0_',\n",
    "                        'svm_m14_f0_',\n",
    "                        'nb_m15_f0_',\n",
    "                        'lrr_m15_f0_',\n",
    "                        'svm_m15_f0_',\n",
    "                        'nb_m16_f0_',\n",
    "                        'lrr_m16_f0_',\n",
    "                        'svm_m16_f0_'\n",
    "                       ]\n",
    "\n",
    "binary_class_suffixes = [\n",
    "                        'nb_le_f1_',\n",
    "                        'nb_ohe_f1_',\n",
    "                        'lrr_le_f1_',\n",
    "                        'lrr_ohe_f1_',\n",
    "                        'svm_le_f1_',\n",
    "                        'svm_ohe_f1_',\n",
    "                        'tree_le_f1_',\n",
    "                        'tree_ohe_f1_'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This block does all of the scoring, last one to update, only cell that needs running\n",
    "for experiment in experiment_model_names:\n",
    "    scoring_dictionary = {}\n",
    "    \n",
    "    for mclass in multi_class_suffixes:\n",
    "        temp_model_name = mclass+experiment\n",
    "        model_name = temp_model_name\n",
    "        \n",
    "        model_data = pd.read_csv('exported_model_files/dataframes/'+model_name+'.csv',dtype=str)\n",
    "        ohe = ohe_main\n",
    "        # Loading test data\n",
    "        if 'le' in model_name:\n",
    "            test_data_t7 = get_label_encoded_data('data/t7.csv',model_name='t7',column_list=column_list,drop_not_happy='H',data_balance=False)[0]\n",
    "        elif 'ohe' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=ohe,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm2' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m2,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm3' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m3,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm4' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m4,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm5' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m5,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm6' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m6,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm7' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m7,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm8' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m8,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm9' in model_name: \n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m9,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm10' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m10,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm11' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m11,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm12' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m12,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm13' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m13,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm14' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m14,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm15' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m15,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "        elif 'm16' in model_name:\n",
    "            test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=m16,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "       \n",
    "        test_data_t7_temp = test_data_t7.copy()[list(model_data.columns)].head(210)\n",
    "\n",
    "        # Loading model files\n",
    "        pkl_file = open('exported_model_files/metadata/'+model_name+'_cat', 'rb')\n",
    "        index_dict = pickle.load(pkl_file)\n",
    "        new_vector = np.zeros(len(index_dict))\n",
    "\n",
    "        pkl_file = open('exported_model_files/models/'+model_name+'.pkl', 'rb')\n",
    "        model = pickle.load(pkl_file)\n",
    "\n",
    "        # Preparing Loading data\n",
    "        test_array = np.array(test_data_t7_temp.drop(axis=1,columns=[\"program\"]))\n",
    "        test_actual = np.array(test_data_t7_temp[\"program\"])\n",
    "        \n",
    "        mclass_t3 = get_mclass_t3(temp_model_name,model,test_array,test_actual)\n",
    "        mclass_RR = get_mclass_rr(temp_model_name,model,test_array,test_actual)\n",
    "        mclass_accuracy = get_mclass_accuracy(temp_model_name,model,test_array,test_actual)\n",
    "        mclass_reassignment = get_mclass_reassignment(temp_model_name,model)\n",
    "        mclass_top2 = get_mclass_topN(temp_model_name,model,test_array,test_actual,2)\n",
    "        mclass_top3 = get_mclass_topN(temp_model_name,model,test_array,test_actual,3)\n",
    "        mclass_top4 = get_mclass_topN(temp_model_name,model,test_array,test_actual,4)\n",
    "        mclass_top5 = get_mclass_topN(temp_model_name,model,test_array,test_actual,5)\n",
    "        mclass_top6 = get_mclass_topN(temp_model_name,model,test_array,test_actual,6)\n",
    "        mclass_top7 = get_mclass_topN(temp_model_name,model,test_array,test_actual,7)\n",
    "        mclass_top8 = get_mclass_topN(temp_model_name,model,test_array,test_actual,8)\n",
    "        mclass_top9 = get_mclass_topN(temp_model_name,model,test_array,test_actual,9)\n",
    "        mclass_top10 = get_mclass_topN(temp_model_name,model,test_array,test_actual,10)\n",
    "        mclass_top11 = get_mclass_topN(temp_model_name,model,test_array,test_actual,11)\n",
    "        mclass_top12 = get_mclass_topN(temp_model_name,model,test_array,test_actual,12)\n",
    "        mclass_top13 = get_mclass_topN(temp_model_name,model,test_array,test_actual,13)\n",
    "        mclass_top14 = get_mclass_topN(temp_model_name,model,test_array,test_actual,14)\n",
    "        mclass_top15 = get_mclass_topN(temp_model_name,model,test_array,test_actual,15)\n",
    "        \n",
    "        scoring_dictionary[mclass+experiment] = {'t3':mclass_t3,\n",
    "                                                 'RR':mclass_RR,\n",
    "                                                 'reassignment':mclass_reassignment,\n",
    "                                                 'accuracy':mclass_accuracy,\n",
    "                                                 'top2':mclass_top2,\n",
    "                                                 'top3':mclass_top3,\n",
    "                                                 'top4':mclass_top4,\n",
    "                                                 'top5':mclass_top5,\n",
    "                                                 'top6':mclass_top6,\n",
    "                                                 'top7':mclass_top7,\n",
    "                                                 'top8':mclass_top8,\n",
    "                                                 'top9':mclass_top9,\n",
    "                                                 'top10':mclass_top10,\n",
    "                                                 'top11':mclass_top11,\n",
    "                                                 'top12':mclass_top12,\n",
    "                                                 'top13':mclass_top13,\n",
    "                                                 'top14':mclass_top14,\n",
    "                                                 'top15':mclass_top15\n",
    "                                                }\n",
    "        print(str(temp_model_name)+\" scored...\")\n",
    "        \n",
    "#     for bclass in binary_class_suffixes:\n",
    "#         temp_model_name = bclass+experiment\n",
    "#         model_name = temp_model_name\n",
    "        \n",
    "#         model_data = pd.read_csv('exported_model_files/dataframes/'+model_name+'.csv',dtype=str)\n",
    "#         ohe = ohe_main\n",
    "\n",
    "#         # Loading test data\n",
    "#         if 'le' in model_name:\n",
    "#             test_data_t7 = get_label_encoded_data('data/t7.csv',model_name='t7',column_list=column_list,drop_not_happy='H',data_balance=False)[0]\n",
    "#         elif 'ohe' in model_name:\n",
    "#             test_data_t7 = get_merged_encoded_data(directory = 'data/t7.csv',model_name ='t7',one_hot_encode=ohe,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "            \n",
    "\n",
    "#         test_data_t7_temp = test_data_t7.copy()[list(model_data.columns)].head(210)\n",
    " \n",
    "#         # Getting average accuracy score\n",
    "#         test_array = np.array(test_data_t7_temp.drop(axis=1,columns=[\"program\"]))\n",
    "#         test_actual = np.array(test_data_t7_temp[\"program\"])\n",
    "        \n",
    "#         bclass_t3 = get_bclass_t3(test_array,model_name,test_actual,test_data_t7)\n",
    "#         bclass_RR = get_bclass_rr(test_array,model_name,test_actual,test_data_t7)\n",
    "#         bclass_accuracy = get_bclass_accuracy(test_array,model_name,test_actual,test_data_t7)\n",
    "#         bclass_reassignment = get_bclass_reassignment(test_array,model_name,test_data_t7)\n",
    "#         scoring_dictionary[bclass+experiment] = {'t3':bclass_t3,'RR':bclass_RR,'accuracy':bclass_accuracy,'reassignment':bclass_reassignment}\n",
    "#         print(str(temp_model_name)+\" scored...\")\n",
    "        \n",
    "    print(\"saving \"+str(experiment)+ \" scores..\")\n",
    "    save_scores(scoring_dictionary,experiment)\n",
    "    b = datetime.datetime.now()\n",
    "    c = b - a\n",
    "    a = datetime.datetime.now()\n",
    "    time_list.append(c)\n",
    "    \n",
    "    \n",
    "print(\"scoring complete.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
 "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in time_list:\n",
    "    print(str(c.seconds)+\" seconds or \"+str(c.seconds/60)+\" mins\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
