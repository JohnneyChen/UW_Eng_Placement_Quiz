{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from data_load import get_encoded_data,get_clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create our feature vector of exact same dimension as our training set. To convert our user input into dummy variables, we should save a dict of the the dummy variables. Later we can populate our feature vector for prediction using this dict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Naiyve Bayes Model with no Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nb_model_basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_encoded_data('quiz_data.csv','nb_model_basic',True)[0]\n",
    "\n",
    "x_df = data.drop(axis=1,columns=[\"program\"])\n",
    "y_df = data[\"program\"]\n",
    "\n",
    "X = np.array(x_df) # convert dataframe into np array\n",
    "y = np.array(y_df) # convert dataframe into np array\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "model = mnb.fit(x_df, y_df) # fit the model using training data\n",
    "\n",
    "cat = data.drop('program',axis=1)\n",
    "index_dict = dict(zip(cat.columns,range(cat.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  2 12 14  5  4  9 14 13  4 10  4  3  5 10 10  6 10 10 10  5 11  9  9\n",
      " 10 11  4  9  8  7  6 12  7  7  7 10 10 13  7  9  9 13 11 14  5 10  2  7\n",
      "  4  9  9  3  9  9 12 10  4  1  3 14 10 12  9  6  3  2  9 10  6 14  9  9\n",
      " 10  7 14  9  0  7 10 10 12  5 14  3  7  2  6  4 11  3  9  9  3  4  9 13\n",
      " 10  9  6  9 12  4  9  2 13  4  5 13 14  1  4  7  4  9 10 10  3 10 10  9\n",
      " 10  9  9 10  8  6 11  4 11  7  5 12  1  4 10 14  8  7  9 14  7  2  2 13\n",
      "  4 13  1  5 14  9  3 12  9  6  1  3 10 11  9  7  2 13 13  9  1 10  1  5\n",
      "  9  2  2  9 14  9 14  4  9 11  5  4 14  4 13  9  5 12  8 14 10  3  3 10\n",
      "  3  4  3 13 11  9 13  9  9 10  3 10 11 11  2  0  5 13 14 14  1  1  9  5\n",
      "  1  9 13  0 12  9  2 14  4 13  3  0  9  1  1 10 10 11 12  5  3  1 12  9\n",
      "  1  7  0  7  9  0  0  1  0 14 13 12 14  1  3  4  5  5  6  7  7  9  5  2\n",
      " 10  1  2  3  5  5  5  9  1  3  9  5  5  7  7 14  3  3  7  4  5  3  9 14\n",
      "  9  7  9  7  4 14  8  4  3  3 14  0  0  0 14  9  3  0  0  1  9  9  3 11\n",
      "  6 14 14 14  0  5  9  9  4  7 11  7  2  5  3  2  7  6 10 11 11  1  9  2\n",
      "  0 11 10 14 14 10  0 14  3  7 10  2  2 10 10  6  4 10  2 10  0 13 12  9\n",
      " 12  5 11  5  0  3  2  2 13  8 13 14 14  0 10 13 10  3 13  4 13  8 10 14\n",
      " 12 14  4  6  4 14  9 10  0  0  4 14  0 10 10  2 13 11  5  2 10  1  7 10\n",
      " 13  0  0 10  6  0 14  2 13  6 14  7  7 13 12  3 13 12 13 13 13 13 12  3\n",
      "  3 12 13  2 13 12  7  2 12  7  3  0  0  3 13 10 13  5  3  2  5 10  2  3\n",
      "  3 10 10 12 12 10 10 10 10  6 12  5  9 14 10  2  6 10 10  0 13 10 10 10\n",
      " 10 13  9  3 14 14  2  2  2 13  9 12  2 10  8  2 12 14  1  9 12  6 14 10\n",
      " 11  3  0  4 12  5 10  9 14  9  7  7 12  7  4 11 10 10  5  3  1  9  3  9\n",
      " 14 10 11 10  0  0 11  6 11 11  0  9 13 11  2 10 11 14  3  3 14  6  6  3\n",
      "  0  3 11  5  9 11 11  5  6  9  9  4 11  7  9 14 14 12 14  0 10  4  0 14\n",
      " 10  9 14 10  9  4  3  0]\n"
     ]
    }
   ],
   "source": [
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [2]\n",
      " [1]\n",
      " [4]\n",
      " [1]\n",
      " [4]\n",
      " [6]\n",
      " [3]\n",
      " [8]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (25,1) and (25,15) not aligned: 1 (dim 1) != 25 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dbf03c0b96fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# print(prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[0m\u001b[1;32m    732\u001b[0m                 self.class_log_prior_)\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (25,1) and (25,15) not aligned: 1 (dim 1) != 25 (dim 0)"
     ]
    }
   ],
   "source": [
    "new_vector = [None] * 25\n",
    "new_vector[0] =  2   # {'problem_type': {'defined': 0, 'investigate': 2, 'discover': 1}}\n",
    "new_vector[1] =  2   #{'creative': {'somewhat_creative': 2, 'creative': 0, 'not_creative': 1}}\n",
    "new_vector[2] =  1   #{'outdoors': {'limited': 1, 'indoors': 0, 'outdoors': 2}}\n",
    "new_vector[3] =  4   #{'career': {'moving_parts': 2, 'sensors': 6, 'programming': 4, 'optimizing': 3, 'resources': 5, 'buildings': 0, 'molecules': 1}}\n",
    "new_vector[4] =  1   #{'group_work': {'occasionally': 1, 'yes': 2, 'no': 0}}\n",
    "new_vector[5] =  4   #{'liked_courses': {'computer_science': 4, 'biology': 1, 'math': 8, 'physics': 9, 'chemistry': 3, 'business': 2, 'autoshop': 0, 'geography': 5, 'visual_arts': 10, 'language_arts': 7, 'history': 6}}\n",
    "new_vector[6] =  6   #{'disliked_courses': {'history': 6, 'visual_arts': 10, 'geography': 5, 'chemistry': 3, 'physics': 9, 'biology': 1, 'language_arts': 7, 'business': 2, 'math': 8, 'computer_science': 4, 'autoshop': 0}}\n",
    "new_vector[7] =  3   #{'programming': {'partial': 3, 'complete': 0, 'no': 2, 'interested': 1}}\n",
    "new_vector[8] =  8   #{'join_clubs': {'robotics': 7, 'nan': 6, 'environment': 4, 'student_council': 8, 'business': 2, 'hacker_club': 5, 'autoshop': 1, 'art/design': 0, 'consulting': 3}}\n",
    "new_vector[9] =  0   #{'not_clubs': {'art/design': 0, 'business': 2, 'student_council': 8, 'autoshop': 1, 'hacker_club': 5, 'environment': 4, 'robotics': 7, 'nan': 6, 'consulting': 3}}\n",
    "new_vector[10] = 1   #{'liked_projects': {'mars_water_treatment': 1, 'prototyping_instrument': 3, 'robot': 4, 'olympic_village': 2, 'battery': 0, 'uber_pool': 6, 'supercomputer': 5}}\n",
    "new_vector[11] = 1   #{'disliked_projects': {'prototyping_instrument': 3, 'mars_water_treatment': 1, 'robot': 4, 'uber_pool': 6, 'olympic_village': 2, 'battery': 0, 'supercomputer': 5}}\n",
    "new_vector[12] = 0   #{'tv_shows': {'big_bang_theory': 0, 'breaking_bad': 1, 'myth_busters': 4, 'silicon_valley': 6, 'planet_earth': 5, 'greys_anatomy': 2, 'house_hunters': 3}}\n",
    "new_vector[13] = 0   #{'alternate_degree': {'cs': 2, 'applied_science': 0, 'health': 8, 'env': 5, 'poli_sci': 12, 'econ': 4, 'math': 11, 'business': 1, 'design': 3, 'visual_arts': 14, 'psych': 13, 'geo': 7, 'fin': 6, 'marketing': 10, 'lit': 9}}\n",
    "new_vector[14] = 1   #{'expensive_equipment': {'yes': 2, 'maybe': 0, 'no': 1}}\n",
    "new_vector[15] = 2   #{'drawing': {'partial': 2, 'bad': 0, 'good': 1}}\n",
    "new_vector[16] = 1   #{'essay': {'yes': 2, 'no': 0, 'partial': 1}}\n",
    "new_vector[17] = 0   #{'architecture': {0: 0, 1: 1}}\n",
    "new_vector[18] = 0   #{'automotive': {1: 1, 0: 0}}\n",
    "new_vector[19] = 1   #{'business': {0: 0, 1: 1}}\n",
    "new_vector[20] = 0   #{'construction': {1: 1, 0: 0}}\n",
    "new_vector[21] = 0   #{'health': {0: 0, 1: 1}}\n",
    "new_vector[22] = 1   #{'environment': {0: 0, 1: 1}}\n",
    "new_vector[23] = 1   #{'manufacturing': {1: 1, 0: 0}}\n",
    "new_vector[24] = 1   #{'technology': {1: 1, 0: 0}}\n",
    "\n",
    "new_vector = np.array(new_vector).reshape(-1, 1)\n",
    "print(new_vector)\n",
    "\n",
    "# print(\"Loading model\")\n",
    "# pkl_file = open('nb_model.pkl', 'rb')\n",
    "# print(pkl_file)\n",
    "# nb_model = pickle.load(pkl_file)\n",
    "# print(nb_model)\n",
    "# prediction = nb_model.predict(new_vector)\n",
    "# print(prediction)\n",
    "\n",
    "model.predict(new_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Basic Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = naive_bayes('quiz_data.csv')[0]\n",
    "with open('exported_model_files/nb_model_basic.pkl', 'wb') as fid:\n",
    "    pickle.dump(nb_model, fid,2)\n",
    "\n",
    "index_dict = naive_bayes('golf_data.csv')[1]\n",
    "\n",
    "with open('exported_model_files/nb_model_basic_cat', 'wb') as fid:\n",
    "    pickle.dump(index_dict, fid,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoded Dictionary\n",
    "{'program': {'mech': 9, 'bmed': 2, 'swe': 12, 'tron': 14, 'cive': 5, 'chem': 4, 'syde': 13, 'msci': 10, 'ce': 3, 'elec': 6, 'nano': 11, 'geo': 8, 'env': 7, 'arch-e': 1, 'arch': 0}}\n",
    "\n",
    "{'happy': {'Yes': 0}}\n",
    "\n",
    "{'problem_type': {'defined': 0, 'investigate': 2, 'discover': 1}}\n",
    "\n",
    "{'creative': {'somewhat_creative': 2, 'creative': 0, 'not_creative': 1}}\n",
    "\n",
    "{'outdoors': {'limited': 1, 'indoors': 0, 'outdoors': 2}}\n",
    "\n",
    "{'career': {'moving_parts': 2, 'sensors': 6, 'programming': 4, 'optimizing': 3, 'resources': 5, 'buildings': 0, 'molecules': 1}}\n",
    "\n",
    "{'group_work': {'occasionally': 1, 'yes': 2, 'no': 0}}\n",
    "\n",
    "{'liked_courses': {'computer_science': 4, 'biology': 1, 'math': 8, 'physics': 9, 'chemistry': 3, 'business': 2, 'autoshop': 0, 'geography': 5, 'visual_arts': 10, 'language_arts': 7, 'history': 6}}\n",
    "\n",
    "{'disliked_courses': {'history': 6, 'visual_arts': 10, 'geography': 5, 'chemistry': 3, 'physics': 9, 'biology': 1, 'language_arts': 7, 'business': 2, 'math': 8, 'computer_science': 4, 'autoshop': 0}}\n",
    "\n",
    "{'programming': {'partial': 3, 'complete': 0, 'no': 2, 'interested': 1}}\n",
    "\n",
    "{'join_clubs': {'robotics': 7, 'nan': 6, 'environment': 4, 'student_council': 8, 'business': 2, 'hacker_club': 5, 'autoshop': 1, 'art/design': 0, 'consulting': 3}}\n",
    "\n",
    "{'not_clubs': {'art/design': 0, 'business': 2, 'student_council': 8, 'autoshop': 1, 'hacker_club': 5, 'environment': 4, 'robotics': 7, 'nan': 6, 'consulting': 3}}\n",
    "\n",
    "{'liked_projects': {'mars_water_treatment': 1, 'prototyping_instrument': 3, 'robot': 4, 'olympic_village': 2, 'battery': 0, 'uber_pool': 6, 'supercomputer': 5}}\n",
    "\n",
    "{'disliked_projects': {'prototyping_instrument': 3, 'mars_water_treatment': 1, 'robot': 4, 'uber_pool': 6, 'olympic_village': 2, 'battery': 0, 'supercomputer': 5}}\n",
    "\n",
    "{'tv_shows': {'big_bang_theory': 0, 'breaking_bad': 1, 'myth_busters': 4, 'silicon_valley': 6, 'planet_earth': 5, 'greys_anatomy': 2, 'house_hunters': 3}}\n",
    "\n",
    "{'alternate_degree': {'cs': 2, 'applied_science': 0, 'health': 8, 'env': 5, 'poli_sci': 12, 'econ': 4, 'math': 11, 'business': 1, 'design': 3, 'visual_arts': 14, 'psych': 13, 'geo': 7, 'fin': 6, 'marketing': 10, 'lit': 9}}\n",
    "\n",
    "{'expensive_equipment': {'yes': 2, 'maybe': 0, 'no': 1}}\n",
    "\n",
    "{'drawing': {'partial': 2, 'bad': 0, 'good': 1}}\n",
    "\n",
    "{'essay': {'yes': 2, 'no': 0, 'partial': 1}}\n",
    "\n",
    "{'architecture': {0: 0, 1: 1}}\n",
    "\n",
    "{'automotive': {1: 1, 0: 0}}\n",
    "\n",
    "{'business': {0: 0, 1: 1}}\n",
    "\n",
    "{'construction': {1: 1, 0: 0}}\n",
    "\n",
    "{'health': {0: 0, 1: 1}}\n",
    "\n",
    "{'environment': {0: 0, 1: 1}}\n",
    "\n",
    "{'manufacturing': {1: 1, 0: 0}}\n",
    "\n",
    "{'technology': {1: 1, 0: 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
