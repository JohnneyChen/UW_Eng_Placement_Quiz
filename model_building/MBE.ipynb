{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import metrics, tree, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold,cross_val_score,train_test_split,LeaveOneOut\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from data_load import *\n",
    "from dictionaries import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_naming_convention = model-type_encoding_directory_datastructure_column-set_version\n",
    "\n",
    "\n",
    "example: nb_le_f0_d0_c0_v0 is a  model which is label encoded using data set 1, column set 1, version 1 on the basic untreated data set for a family of multi-label classifiers\n",
    "\n",
    "model_type will be appended to the front of the model name as it is run through each of the \n",
    "\n",
    "Link to model building log: https://docs.google.com/spreadsheets/d/1py4RVZ0er_JDeJo-oxY29QT6__EWHIeU6zBgp-q8Wog/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/quiz_data.csv'\n",
    "#model_name = 'model-type_encoding_directory_datastructure_column-set_version'\n",
    "experiment_model_name = 'test'\n",
    "\n",
    "column_list = [\n",
    "                'problem_type', \n",
    "                'creative', \n",
    "                'outdoors', \n",
    "                'career',\n",
    "                'group_work', \n",
    "                'liked_courses', \n",
    "                'disliked_courses', \n",
    "                'programming',\n",
    "                'join_clubs', \n",
    "                'not_clubs', \n",
    "                'liked_projects',\n",
    "                'disliked_projects',\n",
    "                'tv_shows', \n",
    "                'alternate_degree', \n",
    "                'expensive_equipment', \n",
    "                'drawing',\n",
    "                'essay', \n",
    "                'architecture', \n",
    "                'automotive', \n",
    "                'business', \n",
    "                'construction',\n",
    "                'health',\n",
    "                'environment', \n",
    "                'manufacturing', \n",
    "                'technology',\n",
    "                'program'\n",
    "                ]\n",
    "\n",
    "data_balance = {\n",
    "                'mech': 10,\n",
    "                'bmed': 10,\n",
    "                'swe': 10,\n",
    "                'tron': 10,\n",
    "                'cive': 10,\n",
    "                'chem': 10,\n",
    "                'syde': 10,\n",
    "                'msci': 10,\n",
    "                'ce': 10,\n",
    "                'elec': 10,\n",
    "                'nano': 10,\n",
    "                'geo': 10,\n",
    "                'env': 10,\n",
    "                'arch-e': 10,\n",
    "                'arch': 10\n",
    "                }\n",
    "# data_balance = False # this is only relevant when we want to use untreated data for code d0\n",
    "\n",
    "data_balance_multiple = 1 # Ratio of other programs to program in binary classifier. 2 means double of other programs, 0.5 means half\n",
    "\n",
    "test_vector = [0] * (len(column_list)-1)\n",
    "test_vector = np.array(test_vector).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoding\n",
    "\n",
    " For each new type of encoding defined (other than the default label encoding) we need to define a new list of variables which are to be one hot encoded. This list name should match the encoding code that you will place in the dictionary in the model building google sheet.\n",
    "\n",
    " For each new type of encoding created, a new code block needs to be added under each model under each classfier family. Then, copy the code for the one hot encoded models and change the one_hot_encode list to the new list you created for this type of encoding. Once all the code blocks are added, you can run those cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe =  [\n",
    "        'problem_type', \n",
    "        'creative', \n",
    "        'outdoors', \n",
    "        'career',\n",
    "        'group_work', \n",
    "        'liked_courses', \n",
    "        'disliked_courses', \n",
    "        'programming',\n",
    "        'join_clubs', \n",
    "        'not_clubs', \n",
    "        'liked_projects',\n",
    "        'disliked_projects',\n",
    "        'tv_shows', \n",
    "        'alternate_degree', \n",
    "        'expensive_equipment', \n",
    "        'drawing',\n",
    "        'essay'\n",
    "        ]\n",
    "\n",
    "m0 =  [\n",
    "        'problem_type', \n",
    "        'creative', \n",
    "        'outdoors', \n",
    "        'career',\n",
    "        'group_work', \n",
    "        'liked_courses', \n",
    "        'disliked_courses', \n",
    "        'programming',\n",
    "        'join_clubs', \n",
    "        'not_clubs', \n",
    "        'liked_projects',\n",
    "        'disliked_projects',\n",
    "        'tv_shows', \n",
    "        'alternate_degree', \n",
    "        'expensive_equipment', \n",
    "        'drawing',\n",
    "        'essay'\n",
    "        ]\n",
    "\n",
    "\n",
    "m1 =  [\n",
    "        'problem_type', \n",
    "        'creative', \n",
    "        'outdoors', \n",
    "        'career',\n",
    "        'group_work', \n",
    "        'liked_courses', \n",
    "        'disliked_courses', \n",
    "        'programming',\n",
    "        'join_clubs', \n",
    "        'not_clubs', \n",
    "        'liked_projects',\n",
    "        'disliked_projects',\n",
    "        'tv_shows', \n",
    "        'alternate_degree', \n",
    "        'expensive_equipment', \n",
    "        'drawing',\n",
    "        'essay'\n",
    "        ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Label Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tron\n",
      "Loading CAT file...\n",
      "Loading model...\n",
      "Results:\n",
      "{'arch': 0.0419, 'arch-e': 0.034, 'bmed': 0.0672, 'ce': 0.1041, 'chem': 0.0629, 'cive': 0.0658, 'elec': 0.0521, 'env': 0.0521, 'geo': 0.0188, 'mech': 0.1142, 'msci': 0.0853, 'nano': 0.0651, 'swe': 0.0564, 'syde': 0.0607, 'tron': 0.1193}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'nb_le_f0_'+ experiment_model_name\n",
    "data = get_label_encoded_data(directory,model_name,column_list,'H')[0]\n",
    "data = data[column_list]\n",
    "\n",
    "x_df = data.drop(axis=1,columns=[\"program\"])\n",
    "y_df = data[\"program\"]\n",
    "\n",
    "X = np.array(x_df) # convert dataframe into np array\n",
    "Y = np.array(y_df) # convert dataframe into np array\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "model = mnb.fit(X, Y) # fit the model using training data\n",
    "\n",
    "cat = data.drop('program',axis=1)\n",
    "cat = dict(zip(cat.columns,range(cat.shape[1])))\n",
    "\n",
    "print(INV_INDEX_PROGRAM[model.predict(test_vector)[0]])\n",
    "\n",
    "save_model(model,cat,model_name)\n",
    "test_model(model_name,test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'nb_ohe_f0_'+ experiment_model_name\n",
    "data = get_merged_encoded_data(directory,model_name,one_hot_encode=ohe,column_list = column_list,drop_not_happy='H')\n",
    "\n",
    "x_df = data.drop(axis=1,columns=[\"program\"])\n",
    "y_df = data[\"program\"]\n",
    "\n",
    "X = np.array(x_df) # convert dataframe into np array\n",
    "Y = np.array(y_df) # convert dataframe into np array\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "model = mnb.fit(X, Y) # fit the model using training data\n",
    "\n",
    "cat = data.drop('program',axis=1)\n",
    "cat = dict(zip(cat.columns,range(cat.shape[1])))\n",
    "\n",
    "save_model(model,cat,model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Label Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msci\n",
      "Loading CAT file...\n",
      "Loading model...\n",
      "Results:\n",
      "{'arch': 0.069, 'arch-e': 0.0499, 'bmed': 0.0445, 'ce': 0.0454, 'chem': 0.1041, 'cive': 0.1137, 'elec': 0.0358, 'env': 0.0511, 'geo': 0.0448, 'mech': 0.0716, 'msci': 0.1308, 'nano': 0.0908, 'swe': 0.0784, 'syde': 0.0372, 'tron': 0.0331}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'lrr_le_f0_'+ experiment_model_name\n",
    "data = get_label_encoded_data(directory,model_name,column_list,'H')[0]\n",
    "\n",
    "x_df = data.drop(axis=1,columns=[\"program\"])\n",
    "y_df = data[\"program\"]\n",
    "\n",
    "X = np.array(x_df) # convert dataframe into np array\n",
    "Y = np.array(y_df) # convert dataframe into np array\n",
    "\n",
    "LRR = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "model = LRR.fit(X, Y) # fit the model using training data\n",
    "\n",
    "cat = data.drop('program',axis=1)\n",
    "cat = dict(zip(cat.columns,range(cat.shape[1])))\n",
    "\n",
    "print(INV_INDEX_PROGRAM[model.predict(test_vector)[0]])\n",
    "\n",
    "save_model(model,cat,model_name)\n",
    "test_model(model_name,test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'lrr_ohe_f0_'+ experiment_model_name\n",
    "data = get_merged_encoded_data(directory,model_name,one_hot_encode=ohe,column_list = column_list,drop_not_happy='H')\n",
    "\n",
    "x_df = data.drop(axis=1,columns=[\"program\"])\n",
    "y_df = data[\"program\"]\n",
    "\n",
    "X = np.array(x_df) # convert dataframe into np array\n",
    "Y = np.array(y_df) # convert dataframe into np array\n",
    "\n",
    "LRR = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "model = LRR.fit(X, Y) # fit the model using training data\n",
    "\n",
    "cat = data.drop('program',axis=1)\n",
    "cat = dict(zip(cat.columns,range(cat.shape[1])))\n",
    "\n",
    "save_model(model,cat,model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine - Label Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mech\n",
      "Loading CAT file...\n",
      "Loading model...\n",
      "Results:\n",
      "{'arch': 0.0324, 'arch-e': 0.0322, 'bmed': 0.0825, 'ce': 0.0585, 'chem': 0.061, 'cive': 0.0887, 'elec': 0.0601, 'env': 0.0267, 'geo': 0.0198, 'mech': 0.1689, 'msci': 0.0817, 'nano': 0.0816, 'swe': 0.0221, 'syde': 0.0565, 'tron': 0.1275}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'svm_le_f0_'+ experiment_model_name\n",
    "data = get_label_encoded_data(directory,model_name,column_list,'H')[0]\n",
    "\n",
    "x_df = data.drop(axis=1,columns=[\"program\"])\n",
    "y_df = data[\"program\"]\n",
    "\n",
    "X = np.array(x_df) # convert dataframe into np array\n",
    "Y = np.array(y_df) # convert dataframe into np array\n",
    "\n",
    "SVM = svm.SVC(probability=True)\n",
    "model = SVM.fit(X, Y) # fit the model using training data\n",
    "\n",
    "cat = data.drop('program',axis=1)\n",
    "cat = dict(zip(cat.columns,range(cat.shape[1])))\n",
    "\n",
    "print(INV_INDEX_PROGRAM[model.predict(test_vector)[0]])\n",
    "\n",
    "save_model(model,cat,model_name)\n",
    "test_model(model_name,test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine - One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'svm_ohe_f0_'+ experiment_model_name\n",
    "data = get_merged_encoded_data(directory,model_name,one_hot_encode=ohe,column_list = column_list,drop_not_happy='H')\n",
    "\n",
    "x_df = data.drop(axis=1,columns=[\"program\"])\n",
    "y_df = data[\"program\"]\n",
    "\n",
    "X = np.array(x_df) # convert dataframe into np array\n",
    "Y = np.array(y_df) # convert dataframe into np array\n",
    "\n",
    "SVM = svm.SVC(probability=True)\n",
    "model = SVM.fit(X, Y) # fit the model using training data\n",
    "\n",
    "cat = data.drop('program',axis=1)\n",
    "cat = dict(zip(cat.columns,range(cat.shape[1])))\n",
    "\n",
    "save_model(model,cat,model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes -  Label Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nb_le_f1_'+experiment_model_name\n",
    "data = get_label_encoded_data(directory,model_name,column_list,'H')[0]\n",
    "mnb = model_type = MultinomialNB()\n",
    "binary_classifier(data,model_name,data_balance_multiple,mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nb_ohe_f1_'+experiment_model_name\n",
    "data = get_merged_encoded_data(directory,model_name,one_hot_encode=ohe,column_list = column_list,drop_not_happy='H')\n",
    "mnb = model_type = MultinomialNB()\n",
    "binary_classifier(data,model_name,data_balance_multiple,mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Label Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lrr_le_f1_'+experiment_model_name\n",
    "data = get_label_encoded_data(directory,model_name,column_list,'H')[0]\n",
    "LRR = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "binary_classifier(data,model_name,data_balance_multiple,LRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lrr_ohe_f1_'+experiment_model_name\n",
    "data = get_merged_encoded_data(directory,model_name,one_hot_encode=ohe,column_list = column_list,drop_not_happy='H')\n",
    "LRR = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "binary_classifier(data,model_name,data_balance_multiple,LRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine - Label Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'svm_le_f1_'+experiment_model_name\n",
    "data = get_label_encoded_data(directory,model_name,column_list,'H')[0]\n",
    "SVM = svm.SVC(probability=True)\n",
    "binary_classifier(data,model_name,data_balance_multiple,SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine - One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'svm_ohe_f1_'+experiment_model_name\n",
    "data = get_merged_encoded_data(directory,model_name,one_hot_encode=ohe,column_list = column_list,drop_not_happy='H')\n",
    "SVM = svm.SVC(probability=True)\n",
    "binary_classifier(data,model_name,data_balance_multiple,SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree -  Label Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'tree_le_f1_'+experiment_model_name\n",
    "data = get_label_encoded_data(directory,model_name,column_list,'H')[0]\n",
    "ent = tree.DecisionTreeClassifier()\n",
    "binary_classifier(data,model_name,data_balance_multiple,ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree - One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'tree_ohe_f1_'+experiment_model_name\n",
    "data = get_merged_encoded_data(directory,model_name,one_hot_encode=ohe,column_list = column_list,drop_not_happy='H')\n",
    "ent = tree.DecisionTreeClassifier()\n",
    "binary_classifier(data,model_name,data_balance_multiple,ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
