{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import metrics, tree, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold,cross_val_score,train_test_split,LeaveOneOut\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from statistics import mean\n",
    "\n",
    "from data_load import *\n",
    "from dictionaries import *\n",
    "from score_models import *\n",
    "\n",
    "import datetime\n",
    "a = datetime.datetime.now()\n",
    "time_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\n",
    "                'problem_type',\n",
    "                'creative',\n",
    "                'outdoors',\n",
    "                'career',\n",
    "                'group_work',\n",
    "                'liked_courses',\n",
    "                'disliked_courses',\n",
    "                'programming',\n",
    "                'join_clubs',\n",
    "                'not_clubs',\n",
    "                'liked_projects',\n",
    "                'disliked_projects',\n",
    "                'tv_shows',\n",
    "                'alternate_degree',\n",
    "                'expensive_equipment',\n",
    "                'drawing',\n",
    "                'essay',\n",
    "                'architecture',\n",
    "                'automotive',\n",
    "                'business',\n",
    "                'construction',\n",
    "                'health',\n",
    "                'environment',\n",
    "                'manufacturing',\n",
    "                'technology',\n",
    "                'new_programming',\n",
    "                'program'\n",
    "                ]\n",
    "\n",
    "ohe_main =  [\n",
    "            'problem_type',\n",
    "            'creative',\n",
    "            'outdoors',\n",
    "            'career',\n",
    "            'group_work',\n",
    "            'liked_courses',\n",
    "            'disliked_courses',\n",
    "            'programming',\n",
    "            'join_clubs',\n",
    "            'not_clubs',\n",
    "            'liked_projects',\n",
    "            'disliked_projects',\n",
    "            'tv_shows',\n",
    "            'alternate_degree',\n",
    "            'expensive_equipment',\n",
    "            'drawing',\n",
    "            'new_programming',\n",
    "            'essay'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_model_names = [\n",
    "                        'd1_b0_nc36_v0'\n",
    "                        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class_suffixes = [\n",
    "                        'nb_le_f0_',\n",
    "                        'nb_ohe_f0_',\n",
    "                        'lrr_le_f0_',\n",
    "                        'lrr_ohe_f0_',\n",
    "                        'svm_le_f0_',\n",
    "                        'svm_ohe_f0_'\n",
    "                       ]\n",
    "\n",
    "binary_class_suffixes = [\n",
    "                        'nb_le_f1_',\n",
    "                        'nb_ohe_f1_',\n",
    "                        'lrr_le_f1_',\n",
    "                        'lrr_ohe_f1_',\n",
    "                        'svm_le_f1_',\n",
    "                        'svm_ohe_f1_',\n",
    "                        'tree_le_f1_',\n",
    "                        'tree_ohe_f1_'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This block does all of the scoring, last one to update, only cell that needs running\n",
    "for experiment in experiment_model_names:\n",
    "    scoring_dictionary = {}\n",
    "    \n",
    "    for mclass in multi_class_suffixes:\n",
    "        temp_model_name = mclass+experiment\n",
    "        model_name = temp_model_name\n",
    "        \n",
    "        model_data = pd.read_csv('exported_model_files/dataframes/'+model_name+'.csv',dtype=str)\n",
    "        ohe = ohe_main\n",
    "        # Loading test data\n",
    "        if 'le' in model_name:\n",
    "            test_data_t3 = get_label_encoded_data('data/t3.csv',model_name='t3',column_list=column_list,drop_not_happy='H',data_balance=False)[0]\n",
    "        elif 'ohe' in model_name:\n",
    "            test_data_t3 = get_merged_encoded_data(directory = 'data/t3.csv',model_name ='t3',one_hot_encode=ohe,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "            \n",
    "        test_data_t3_temp = test_data_t3.copy()[list(model_data.columns)].head(90)\n",
    "\n",
    "        # Loading model files\n",
    "        pkl_file = open('exported_model_files/metadata/'+model_name+'_cat', 'rb')\n",
    "        index_dict = pickle.load(pkl_file)\n",
    "        new_vector = np.zeros(len(index_dict))\n",
    "\n",
    "        pkl_file = open('exported_model_files/models/'+model_name+'.pkl', 'rb')\n",
    "        model = pickle.load(pkl_file)\n",
    "\n",
    "        # Preparing Loading data\n",
    "        test_array = np.array(test_data_t3_temp.drop(axis=1,columns=[\"program\"]))\n",
    "        test_actual = np.array(test_data_t3_temp[\"program\"])\n",
    "        \n",
    "        mclass_t3 = get_mclass_t3(temp_model_name,model,test_array,test_actual)\n",
    "        mclass_RR = get_mclass_rr(temp_model_name,model,test_array,test_actual)\n",
    "        mclass_accuracy = get_mclass_accuracy(temp_model_name,model,test_array,test_actual)\n",
    "#         mclass_reassignment = get_mclass_reassignment(temp_model_name,model)\n",
    "        mclass_top2 = get_mclass_topN(temp_model_name,model,test_array,test_actual,2)\n",
    "        mclass_top3 = get_mclass_topN(temp_model_name,model,test_array,test_actual,3)\n",
    "        mclass_top4 = get_mclass_topN(temp_model_name,model,test_array,test_actual,4)\n",
    "        mclass_top5 = get_mclass_topN(temp_model_name,model,test_array,test_actual,5)\n",
    "        mclass_top6 = get_mclass_topN(temp_model_name,model,test_array,test_actual,6)\n",
    "        mclass_top7 = get_mclass_topN(temp_model_name,model,test_array,test_actual,7)\n",
    "        mclass_top8 = get_mclass_topN(temp_model_name,model,test_array,test_actual,8)\n",
    "        mclass_top9 = get_mclass_topN(temp_model_name,model,test_array,test_actual,9)\n",
    "        mclass_top10 = get_mclass_topN(temp_model_name,model,test_array,test_actual,10)\n",
    "        mclass_top11 = get_mclass_topN(temp_model_name,model,test_array,test_actual,11)\n",
    "        mclass_top12 = get_mclass_topN(temp_model_name,model,test_array,test_actual,12)\n",
    "        mclass_top13 = get_mclass_topN(temp_model_name,model,test_array,test_actual,13)\n",
    "        mclass_top14 = get_mclass_topN(temp_model_name,model,test_array,test_actual,14)\n",
    "        mclass_top15 = get_mclass_topN(temp_model_name,model,test_array,test_actual,15)\n",
    "        \n",
    "        scoring_dictionary[mclass+experiment] = {'t3':mclass_t3,\n",
    "                                                 'RR':mclass_RR,\n",
    "#                                                  'reassignment':mclass_reassignment,\n",
    "                                                 'accuracy':mclass_accuracy,\n",
    "                                                 'top2':mclass_top2,\n",
    "                                                 'top3':mclass_top3,\n",
    "                                                 'top4':mclass_top4,\n",
    "                                                 'top5':mclass_top5,\n",
    "                                                 'top6':mclass_top6,\n",
    "                                                 'top7':mclass_top7,\n",
    "                                                 'top8':mclass_top8,\n",
    "                                                 'top9':mclass_top9,\n",
    "                                                 'top10':mclass_top10,\n",
    "                                                 'top11':mclass_top11,\n",
    "                                                 'top12':mclass_top12,\n",
    "                                                 'top13':mclass_top13,\n",
    "                                                 'top14':mclass_top14,\n",
    "                                                 'top15':mclass_top15\n",
    "                                                }\n",
    "        print(str(temp_model_name)+\" scored...\")\n",
    "        \n",
    "#     for bclass in binary_class_suffixes:\n",
    "#         temp_model_name = bclass+experiment\n",
    "#         model_name = temp_model_name\n",
    "        \n",
    "#         model_data = pd.read_csv('exported_model_files/dataframes/'+model_name+'.csv',dtype=str)\n",
    "#         ohe = ohe_main\n",
    "\n",
    "#         # Loading test data\n",
    "#         if 'le' in model_name:\n",
    "#             test_data_t3 = get_label_encoded_data('data/t3.csv',model_name='t3',column_list=column_list,drop_not_happy='H',data_balance=False)[0]\n",
    "#         elif 'ohe' in model_name:\n",
    "#             test_data_t3 = get_merged_encoded_data(directory = 'data/t3.csv',model_name ='t3',one_hot_encode=ohe,column_list = column_list,drop_not_happy='H',data_balance=False)\n",
    "            \n",
    "\n",
    "#         test_data_t3_temp = test_data_t3.copy()[list(model_data.columns)].head(210)\n",
    " \n",
    "#         # Getting average accuracy score\n",
    "#         test_array = np.array(test_data_t3_temp.drop(axis=1,columns=[\"program\"]))\n",
    "#         test_actual = np.array(test_data_t3_temp[\"program\"])\n",
    "        \n",
    "#         bclass_t3 = get_bclass_t3(test_array,model_name,test_actual,test_data_t3)\n",
    "#         bclass_RR = get_bclass_rr(test_array,model_name,test_actual,test_data_t3)\n",
    "#         bclass_accuracy = get_bclass_accuracy(test_array,model_name,test_actual,test_data_t3)\n",
    "#         bclass_reassignment = get_bclass_reassignment(test_array,model_name,test_data_t3)\n",
    "#         scoring_dictionary[bclass+experiment] = {'t3':bclass_t3,'RR':bclass_RR,'accuracy':bclass_accuracy,'reassignment':bclass_reassignment}\n",
    "#         print(str(temp_model_name)+\" scored...\")\n",
    "        \n",
    "    print(\"saving \"+str(experiment)+ \" scores..\")\n",
    "    save_scores(scoring_dictionary,experiment)\n",
    "    b = datetime.datetime.now()\n",
    "    c = b - a\n",
    "    a = datetime.datetime.now()\n",
    "    time_list.append(c)\n",
    "    \n",
    "    \n",
    "print(\"scoring complete.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in time_list:\n",
    "    print(str(c.seconds)+\" seconds or \"+str(c.seconds/60)+\" mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
